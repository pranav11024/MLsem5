{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0eb9eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def summation_unit(inputs, weights):\n",
    "    return sum(i * w for i, w in zip(inputs, weights))\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def bipolar_step_function(x):\n",
    "    return 1 if x >= 0 else -1\n",
    "\n",
    "def sigmoid_function(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def tanh_function(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def relu_function(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def leaky_relu_function(x):\n",
    "    return x if x >= 0 else 0.01 * x\n",
    "\n",
    "def comparator_unit(predicted, actual):\n",
    "    return actual - predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa53f47a-56cf-443a-a9f0-f82b7ebd128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_and_gate(inputs, outputs, epochs=1000, lr=0.05):\n",
    "    weights = [10, 0.2, -0.75]\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(len(inputs)):\n",
    "            summation = summation_unit([1] + inputs[i], weights)\n",
    "            prediction = step_function(summation)\n",
    "            error = comparator_unit(prediction, outputs[i])\n",
    "            total_error += error ** 2\n",
    "            for j in range(len(weights)):\n",
    "                weights[j] += lr * error * ([1] + inputs[i])[j]\n",
    "        if total_error <= 0.002:\n",
    "            break\n",
    "    return weights, epoch\n",
    "\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "outputs = [0, 0, 0, 1]\n",
    "weights, epochs = train_perceptron_and_gate(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5e82110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_activation(inputs, outputs, activation_func, epochs=1000, lr=0.05):\n",
    "    weights = [10, 0.2, -0.75]\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(len(inputs)):\n",
    "            summation = summation_unit([1] + inputs[i], weights)\n",
    "            prediction = activation_func(summation)\n",
    "            error = comparator_unit(prediction, outputs[i])\n",
    "            total_error += error ** 2\n",
    "            for j in range(len(weights)):\n",
    "                weights[j] += lr * error * ([1] + inputs[i])[j]\n",
    "        if total_error <= 0.002:\n",
    "            break\n",
    "    return weights, epoch\n",
    "\n",
    "# Example using Sigmoid Function\n",
    "weights, epochs = train_with_activation(inputs, outputs, sigmoid_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5ceefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1 * i for i in range(1, 11)]\n",
    "iterations = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    _, epoch = train_perceptron_and_gate(inputs, outputs, lr=lr)\n",
    "    iterations.append(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ce3b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_xor = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "outputs_xor = [0, 1, 1, 0]\n",
    "weights, epochs = train_perceptron_and_gate(inputs_xor, outputs_xor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a95e8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_customers(data, labels, epochs=1000, lr=0.05):\n",
    "    weights = [0.1, 0.2, 0.3, 0.4]  # Example initial weights\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(len(data)):\n",
    "            summation = summation_unit([1] + data[i], weights)\n",
    "            prediction = sigmoid_function(summation)\n",
    "            error = comparator_unit(prediction, labels[i])\n",
    "            total_error += error ** 2\n",
    "            for j in range(len(weights)):\n",
    "                weights[j] += lr * error * ([1] + data[i])[j]\n",
    "        if total_error <= 0.002:\n",
    "            break\n",
    "    return weights, epoch\n",
    "\n",
    "customer_data = [\n",
    "    [20, 6, 2],\n",
    "    [16, 3, 6],\n",
    "    [27, 6, 2],\n",
    "    [19, 1, 2],\n",
    "    [24, 4, 2],\n",
    "    [22, 1, 5],\n",
    "    [15, 4, 2],\n",
    "    [18, 4, 2],\n",
    "    [21, 1, 4],\n",
    "    [16, 2, 4]\n",
    "]\n",
    "\n",
    "high_value_labels = [1, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "weights, epochs = train_perceptron_customers(customer_data, high_value_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81f05a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pseudo_inverse_solution(data, labels):\n",
    "    X = np.array([[1] + d for d in data])\n",
    "    Y = np.array(labels)\n",
    "    pseudo_inv = np.linalg.pinv(X)\n",
    "    weights = np.dot(pseudo_inv, Y)\n",
    "    return weights\n",
    "\n",
    "weights_pseudo = pseudo_inverse_solution(customer_data, high_value_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59840c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def train_nn_and_gate(inputs, outputs, epochs=1000, lr=0.05):\n",
    "    weights_input_hidden = [0.5, -0.6, 0.2]\n",
    "    weights_hidden_output = [0.4, -0.7]\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(len(inputs)):\n",
    "            hidden_input = summation_unit([1] + inputs[i], weights_input_hidden)\n",
    "            hidden_output = sigmoid_function(hidden_input)\n",
    "            output_input = summation_unit([1, hidden_output], weights_hidden_output)\n",
    "            output = sigmoid_function(output_input)\n",
    "            error = comparator_unit(output, outputs[i])\n",
    "            total_error += error ** 2\n",
    "            delta_output = error * sigmoid_derivative(output)\n",
    "            delta_hidden = delta_output * sigmoid_derivative(hidden_output) * weights_hidden_output[1]\n",
    "            weights_hidden_output[0] += lr * delta_output * 1\n",
    "            weights_hidden_output[1] += lr * delta_output * hidden_output\n",
    "            for j in range(len(weights_input_hidden)):\n",
    "                weights_input_hidden[j] += lr * delta_hidden * ([1] + inputs[i])[j]\n",
    "        if total_error <= 0.002:\n",
    "            break\n",
    "    return weights_input_hidden, weights_hidden_output, epoch\n",
    "\n",
    "weights_input_hidden, weights_hidden_output, epochs = train_nn_and_gate(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b94eee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_input_hidden, weights_hidden_output, epochs = train_nn_and_gate(inputs_xor, outputs_xor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96ace777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_2_outputs(inputs, outputs, epochs=1000, lr=0.05):\n",
    "    weights = [[0.1, 0.2, -0.1], [0.05, 0.3, -0.25]]\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(len(inputs)):\n",
    "            summation_1 = summation_unit([1] + inputs[i], weights[0])\n",
    "            summation_2 = summation_unit([1] + inputs[i], weights[1])\n",
    "            prediction_1 = step_function(summation_1)\n",
    "            prediction_2 = step_function(summation_2)\n",
    "            error_1 = comparator_unit(prediction_1, outputs[i][0])\n",
    "            error_2 = comparator_unit(prediction_2, outputs[i][1])\n",
    "            total_error += error_1 ** 2 + error_2 ** 2\n",
    "            for j in range(len(weights[0])):\n",
    "                weights[0][j] += lr * error_1 * ([1] + inputs[i])[j]\n",
    "                weights[1][j] += lr * error_2 * ([1] + inputs[i])[j]\n",
    "        if total_error <= 0.002:\n",
    "            break\n",
    "    return weights, epoch\n",
    "\n",
    "outputs_2 = [[1, 0], [1, 0], [1, 0], [0, 1]]  # Example for AND Gate logic\n",
    "weights, epochs = train_perceptron_2_outputs(inputs, outputs_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c153a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# AND Gate using MLPClassifier\n",
    "mlp_and = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='sgd', max_iter=1000)\n",
    "mlp_and.fit(inputs, outputs)\n",
    "and_predictions = mlp_and.predict(inputs)\n",
    "\n",
    "# XOR Gate using MLPClassifier\n",
    "mlp_xor = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='sgd', max_iter=1000)\n",
    "mlp_xor.fit(inputs_xor, outputs_xor)\n",
    "xor_predictions = mlp_xor.predict(inputs_xor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3839109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp_project = MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', solver='sgd', max_iter=1000)\n",
    "mlp_project.fit(customer_data, high_value_labels)\n",
    "project_predictions = mlp_project.predict(customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a893b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Perceptron for AND Gate Logic...\n",
      "Weights after training: [-0.10000000000000765, 0.1000000000000001, 0.05000000000000032]\n",
      "Epochs to converge: 129\n",
      "\n",
      "Training Perceptron for XOR Gate Logic...\n",
      "Weights after training for XOR: [0.09999999999999236, -0.09999999999999969, -0.09999999999999969]\n",
      "Epochs to converge: 999\n",
      "\n",
      "Training Perceptron for Customer Data...\n",
      "Weights after training customer data: [-0.18250271389279019, -1.3365214891771673, 9.012435167930922, -0.0533006109983556]\n",
      "Epochs to converge: 122\n",
      "\n",
      "Comparing Weights with Pseudo-Inverse Method...\n",
      "Weights from pseudo-inverse: [ 0.1139903  -0.02342675  0.2607237   0.03727212]\n",
      "\n",
      "Training Neural Network for AND Gate...\n",
      "Weights (input-hidden) after training: [1.065546038523148, -1.6039201646705568, -1.103603376806378]\n",
      "Weights (hidden-output) after training: [0.05922996021700995, -2.45894383324324]\n",
      "Epochs to converge: 999\n",
      "\n",
      "Training Neural Network for XOR Gate...\n",
      "Weights (input-hidden) after training XOR: [0.5616681385599502, -0.5607471249996671, 0.3093566144322304]\n",
      "Weights (hidden-output) after training XOR: [0.40664727753188135, -0.6764470646287483]\n",
      "Epochs to converge: 999\n",
      "\n",
      "Training Perceptron with 2 Output Nodes for AND Gate...\n",
      "Weights for output 1 after training: [0.10000000000000002, -0.09999999999999999, -0.10000000000000002]\n",
      "Weights for output 2 after training: [-0.2, 0.15000000000000002, 0.04999999999999999]\n",
      "Epochs to converge: 9\n",
      "\n",
      "Using MLPClassifier for AND Gate...\n",
      "Predictions for AND Gate using MLPClassifier: [0 0 0 0]\n",
      "\n",
      "Using MLPClassifier for XOR Gate...\n",
      "Predictions for XOR Gate using MLPClassifier: [0 1 0 1]\n",
      "\n",
      "Predictions for Project Data using MLPClassifier: [1 0 1 0 1 0 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1232, 5376), Labels shape: (1232,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_project_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    X = df.iloc[:, :-1].values  # Assuming the last column is the target variable\n",
    "    y = df.iloc[:, -1].values   # Target column (assumed to be the last one)\n",
    "    return X, y\n",
    "\n",
    "# AND Gate Example (A2)\n",
    "print(\"Training Perceptron for AND Gate Logic...\")\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "outputs = [0, 0, 0, 1]\n",
    "weights, epochs = train_perceptron_and_gate(inputs, outputs)\n",
    "print(f\"Weights after training: {weights}\")\n",
    "print(f\"Epochs to converge: {epochs}\\n\")\n",
    "# XOR Gate Example (A5)\n",
    "print(\"Training Perceptron for XOR Gate Logic...\")\n",
    "inputs_xor = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "outputs_xor = [0, 1, 1, 0]\n",
    "weights_xor, epochs_xor = train_perceptron_and_gate(inputs_xor, outputs_xor)\n",
    "print(f\"Weights after training for XOR: {weights_xor}\")\n",
    "print(f\"Epochs to converge: {epochs_xor}\\n\")\n",
    "# Customer Data Example (A6)\n",
    "print(\"Training Perceptron for Customer Data...\")\n",
    "customer_data = [\n",
    "    [20, 6, 2],\n",
    "    [16, 3, 6],\n",
    "    [27, 6, 2],\n",
    "    [19, 1, 2],\n",
    "    [24, 4, 2],\n",
    "    [22, 1, 5],\n",
    "    [15, 4, 2],\n",
    "    [18, 4, 2],\n",
    "    [21, 1, 4],\n",
    "    [16, 2, 4]\n",
    "]\n",
    "high_value_labels = [1, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
    "weights_customers, epochs_customers = train_perceptron_customers(customer_data, high_value_labels)\n",
    "print(f\"Weights after training customer data: {weights_customers}\")\n",
    "print(f\"Epochs to converge: {epochs_customers}\\n\")\n",
    "# Comparing with Matrix Pseudo-Inverse (A7)\n",
    "print(\"Comparing Weights with Pseudo-Inverse Method...\")\n",
    "weights_pseudo = pseudo_inverse_solution(customer_data, high_value_labels)\n",
    "print(f\"Weights from pseudo-inverse: {weights_pseudo}\\n\")\n",
    "# Neural Network for AND Gate (A8)\n",
    "print(\"Training Neural Network for AND Gate...\")\n",
    "weights_input_hidden, weights_hidden_output, epochs_nn = train_nn_and_gate(inputs, outputs)\n",
    "print(f\"Weights (input-hidden) after training: {weights_input_hidden}\")\n",
    "print(f\"Weights (hidden-output) after training: {weights_hidden_output}\")\n",
    "print(f\"Epochs to converge: {epochs_nn}\\n\")\n",
    "# Neural Network for XOR Gate (A9)\n",
    "print(\"Training Neural Network for XOR Gate...\")\n",
    "weights_input_hidden_xor, weights_hidden_output_xor, epochs_nn_xor = train_nn_and_gate(inputs_xor, outputs_xor)\n",
    "print(f\"Weights (input-hidden) after training XOR: {weights_input_hidden_xor}\")\n",
    "print(f\"Weights (hidden-output) after training XOR: {weights_hidden_output_xor}\")\n",
    "print(f\"Epochs to converge: {epochs_nn_xor}\\n\")\n",
    "# Perceptron with 2 Output Nodes (A10)\n",
    "print(\"Training Perceptron with 2 Output Nodes for AND Gate...\")\n",
    "outputs_2 = [[1, 0], [1, 0], [1, 0], [0, 1]]\n",
    "weights_2_outputs, epochs_2_outputs = train_perceptron_2_outputs(inputs, outputs_2)\n",
    "print(f\"Weights for output 1 after training: {weights_2_outputs[0]}\")\n",
    "print(f\"Weights for output 2 after training: {weights_2_outputs[1]}\")\n",
    "print(f\"Epochs to converge: {epochs_2_outputs}\\n\")\n",
    "# Using MLPClassifier for AND Gate (A11)\n",
    "print(\"Using MLPClassifier for AND Gate...\")\n",
    "mlp_and = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='sgd', max_iter=1000)\n",
    "mlp_and.fit(inputs, outputs)\n",
    "and_predictions = mlp_and.predict(inputs)\n",
    "print(f\"Predictions for AND Gate using MLPClassifier: {and_predictions}\\n\")\n",
    "# Using MLPClassifier for XOR Gate (A11)\n",
    "print(\"Using MLPClassifier for XOR Gate...\")\n",
    "mlp_xor = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='sgd', max_iter=1000)\n",
    "mlp_xor.fit(inputs_xor, outputs_xor)\n",
    "xor_predictions = mlp_xor.predict(inputs_xor)\n",
    "print(f\"Predictions for XOR Gate using MLPClassifier: {xor_predictions}\\n\")\n",
    "#A12\n",
    "print(f\"Predictions for Project Data using MLPClassifier: {project_predictions}\")\n",
    "file_path = r\"C:\\Users\\prana\\Desktop\\ML proj\\trial0\\v2\\CC_vector_v2.xlsx\"\n",
    "X, y = load_project_data(file_path)\n",
    "print(f\"Data shape: {X.shape}, Labels shape: {y.shape}\\n\")\n",
    "\n",
    "mlp_project = MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', solver='sgd', max_iter=1000)\n",
    "mlp_project.fit(X, y)\n",
    "project_predictions = mlp_project.predict(X)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
